{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit(), and its inverse logit()\n",
    "import scipy.special\n",
    "# library for plotting arrays\n",
    "import matplotlib.pyplot\n",
    "# ensure the plots are inside this notebook, not an external window\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "# Comment filled in\n",
    "(train_future, train_label), (test_future, test_label) = mnist.load_data()\n",
    "train_future = train_future[:10000]\n",
    "train_label = train_label[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# How many pieces of image data do you have learning data?\n",
    "print(len(train_future))\n",
    "\n",
    "# How many correct labels do you have for learning data?\n",
    "print(len(train_label))\n",
    "\n",
    "# How many image data of verification data are there?\n",
    "print(len(test_future))\n",
    "\n",
    "# How many correct labels do the validation data have?\n",
    "print(len(test_label))\n",
    "\n",
    "# Let's look at the first image data of the learning data\n",
    "print(train_future[0])\n",
    "\n",
    "#Let's look at the first correct answer label of the learning data\n",
    "print(train_label[0])\n",
    "\n",
    "# If you have time, let's look at other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at the image for reference, it looks like this\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the first 10 images\n",
    "images=train_future[0:10]\n",
    "labels=train_label[0:10]\n",
    "\n",
    "fig=plt.figure(figsize=(8,4))\n",
    "subplot=None\n",
    "for c,(image,label) in enumerate(zip(images,labels)):\n",
    "    subplot=fig.add_subplot(2,5,c+1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % (label))\n",
    "    subplot.imshow(image.reshape(28,28),vmin=0,vmax=255,\n",
    "                  cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of array of downloaded image data\n",
      "(10000, 28, 28)\n",
      "Number of array of processed image data\n",
      "(10000, 784)\n",
      "First piece of learning data\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
      " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215687\n",
      " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
      " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
      " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313726\n",
      " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.13725491 0.94509804\n",
      " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
      " 0.5882353  0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
      " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.5803922\n",
      " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058825\n",
      " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
      " 0.3137255  0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333336 0.99215686\n",
      " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "State of the first label of learning data\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "train_future_data = train_future.astype('float32')\n",
    "# \n",
    "test_future_data = test_future.astype('float32')\n",
    "# \n",
    "\n",
    "train_future_data = train_future_data / 255\n",
    "# \n",
    "test_future_data = test_future_data / 255\n",
    "# \n",
    "\n",
    "\n",
    "train_future_data = train_future_data.reshape(10000, 784)\n",
    "# \n",
    "\n",
    "test_future_data = test_future_data.reshape(10000, 784)\n",
    "# \n",
    "\n",
    "# Confirm number of array\n",
    "print(\"Number of array of downloaded image data\")\n",
    "print(train_future.shape)\n",
    "print(\"Number of array of processed image data\")\n",
    "print(train_future_data.shape)\n",
    "print(\"First piece of learning data\")\n",
    "print(train_future_data[0])\n",
    "\n",
    "# Convert to one hot vector format\n",
    "train_label_data = keras.utils.to_categorical(train_label, 10)\n",
    "test_label_data = keras.utils.to_categorical(test_label, 10)\n",
    "\n",
    "print(\"State of the first label of learning data\")\n",
    "print(train_label_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        self.inverse_activation_function = lambda x: scipy.special.logit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) \n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.who += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(hidden_outputs))\n",
    "        \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), numpy.transpose(inputs))\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs\n",
    "    \n",
    "    \n",
    "    # backquery the neural network\n",
    "    # we'll use the same termnimology to each item, \n",
    "    # eg target are the values at the right of the network, albeit used as input\n",
    "    # eg hidden_output is the signal to the right of the middle nodes\n",
    "    def backquery(self, targets_list):\n",
    "        # transpose the targets list to a vertical array\n",
    "        final_outputs = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate the signal into the final output layer\n",
    "        final_inputs = self.inverse_activation_function(final_outputs)\n",
    "\n",
    "        # calculate the signal out of the hidden layer\n",
    "        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        hidden_outputs -= numpy.min(hidden_outputs)\n",
    "        hidden_outputs /= numpy.max(hidden_outputs)\n",
    "        hidden_outputs *= 0.98\n",
    "        hidden_outputs += 0.01\n",
    "        \n",
    "        # calculate the signal into the hidden layer\n",
    "        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n",
    "        \n",
    "        # calculate the signal out of the input layer\n",
    "        inputs = numpy.dot(self.wih.T, hidden_inputs)\n",
    "        # scale them back to 0.01 to .99\n",
    "        inputs -= numpy.min(inputs)\n",
    "        inputs /= numpy.max(inputs)\n",
    "        inputs *= 0.98\n",
    "        inputs += 0.01\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 200\n",
    "output_nodes = 10\n",
    "\n",
    "# learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_list = train_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "# train the neural network\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    print(\"Epoch:\", e)\n",
    "    for record in training_data_list:\n",
    "        inputs = train_future_data\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        n.train(inputs, targets)\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the mnist test data CSV file into a list\n",
    "test_data_file = open(\"mnist_dataset/mnist_test_10.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the neural network\n",
    "\n",
    "# scorecard for how well the network performs, initially empty\n",
    "scorecard = []\n",
    "\n",
    "# go through all the records in the test data set\n",
    "for record in test_data_list:\n",
    "    # split the record by the ',' commas\n",
    "    all_values = record.split(',')\n",
    "    # correct answer is first value\n",
    "    correct_label = int(all_values[0])\n",
    "    # scale and shift the inputs\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    # query the network\n",
    "    outputs = n.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    label = numpy.argmax(outputs)\n",
    "    # append correct or incorrect to list\n",
    "    if (label == correct_label):\n",
    "        # network's answer matches correct answer, add 1 to scorecard\n",
    "        scorecard.append(1)\n",
    "    else:\n",
    "        # network's answer doesn't match correct answer, add 0 to scorecard\n",
    "        scorecard.append(0)\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance =  0.2\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance score, the fraction of correct answers\n",
    "scorecard_array = numpy.asarray(scorecard)\n",
    "print (\"performance = \", scorecard_array.sum() / scorecard_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef99a5ed68>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run the network backwards, given a label, see what image it produces\n",
    "\n",
    "# label to test\n",
    "label = 0\n",
    "# create the output signals for this label\n",
    "targets = numpy.zeros(output_nodes) + 0.01\n",
    "# all_values[0] is the target label for this record\n",
    "targets[label] = 0.99\n",
    "print(targets)\n",
    "\n",
    "# get image data\n",
    "image_data = n.backquery(targets)\n",
    "\n",
    "# plot image data\n",
    "matplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "<td style=\"border-style: none;\">\n",
       "<div style=\"border: solid 2px #666; width: 143px; height: 144px;\">\n",
       "<canvas width=\"140\" height=\"140\"></canvas>\n",
       "</td>\n",
       "<td style=\"border-style: none;\">\n",
       "<button onclick=\"clear_value()\">Clear</button>\n",
       "</td>\n",
       "</table>\n",
       "\n",
       "<script type=\"text/Javascript\">\n",
       "\tvar pixels = [];\n",
       "\tfor(var i = 0; i < 28*28; i++) pixels[i] = 0\n",
       "\tvar click=0;\n",
       "\tvar button_state=0;\n",
       "    \n",
       "\tvar canvas = document.querySelector(\"canvas\");\n",
       "    \n",
       "    canvas.addEventListener(\"mousedown\", function(e){\n",
       "        button_state=1;\n",
       "    });\n",
       "    canvas.addEventListener(\"mouseup\", function(e){\n",
       "        button_state=0;\n",
       "    });\n",
       "    canvas.addEventListener(\"mouseleave\", function(e){\n",
       "        button_state=0;\n",
       "    });\n",
       "\t\n",
       "\tcanvas.addEventListener(\"mousemove\", function(e){\n",
       "\t\tconsole.log(button_state);\n",
       "        if(button_state){\n",
       "            click = 1;\n",
       "\t\t\tcanvas.getContext(\"2d\").fillStyle = \"rgb(0,0,0)\";\n",
       "\t\t\tcanvas.getContext(\"2d\").fillRect(e.offsetX, e.offsetY, 8, 8);\n",
       "\t\t\tx = Math.floor(e.offsetY * 0.2)\n",
       "\t\t\ty = Math.floor(e.offsetX * 0.2) + 1\n",
       "            console.log(x)\n",
       "            \n",
       "\t\t\tfor(var dy = 0; dy < 2; dy++){\n",
       "\t\t\t\tfor(var dx = 0; dx < 2; dx++){\n",
       "\t\t\t\t\tif((x + dx < 28) && (y + dy < 28)){\n",
       "\t\t\t\t\t\tpixels[(y+dy) + (x+dx)*28] = 1\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t}else{\n",
       "            if(click == 1) set_value()\n",
       "\t\t\tclick = 0;\n",
       "\t\t}\n",
       "\t});\n",
       "\t\n",
       "\tfunction set_value(){\n",
       "\t\tvar result = \"\"\n",
       "\t\tfor(var i=0;i<28*28;i++) result += pixels[i] + \",\"\n",
       "\t\tvar kernel = IPython.notebook.kernel;\n",
       "\t\tkernel.execute(\"image = [\" + result + \"]\");\n",
       "\t}\n",
       "\t\n",
       "\tfunction clear_value(){\n",
       "        canvas.getContext(\"2d\").fillStyle = \"rgb(255,255,255)\";\n",
       "\t\tcanvas.getContext(\"2d\").fillRect(0,0,140,140);\n",
       "\t\tfor(var i=0;i<28*28;i++) pixels[i]=0\n",
       "\t}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_form = \"\"\"\n",
    "<table>\n",
    "<td style=\"border-style: none;\">\n",
    "<div style=\"border: solid 2px #666; width: 143px; height: 144px;\">\n",
    "<canvas width=\"140\" height=\"140\"></canvas>\n",
    "</td>\n",
    "<td style=\"border-style: none;\">\n",
    "<button onclick=\"clear_value()\">Clear</button>\n",
    "</td>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "javascript=\"\"\"\n",
    "<script type=\"text/Javascript\">\n",
    "\tvar pixels = [];\n",
    "\tfor(var i = 0; i < 28*28; i++) pixels[i] = 0\n",
    "\tvar click=0;\n",
    "\tvar button_state=0;\n",
    "    \n",
    "\tvar canvas = document.querySelector(\"canvas\");\n",
    "    \n",
    "    canvas.addEventListener(\"mousedown\", function(e){\n",
    "        button_state=1;\n",
    "    });\n",
    "    canvas.addEventListener(\"mouseup\", function(e){\n",
    "        button_state=0;\n",
    "    });\n",
    "    canvas.addEventListener(\"mouseleave\", function(e){\n",
    "        button_state=0;\n",
    "    });\n",
    "\t\n",
    "\tcanvas.addEventListener(\"mousemove\", function(e){\n",
    "\t\tconsole.log(button_state);\n",
    "        if(button_state){\n",
    "            click = 1;\n",
    "\t\t\tcanvas.getContext(\"2d\").fillStyle = \"rgb(0,0,0)\";\n",
    "\t\t\tcanvas.getContext(\"2d\").fillRect(e.offsetX, e.offsetY, 8, 8);\n",
    "\t\t\tx = Math.floor(e.offsetY * 0.2)\n",
    "\t\t\ty = Math.floor(e.offsetX * 0.2) + 1\n",
    "            console.log(x)\n",
    "            \n",
    "\t\t\tfor(var dy = 0; dy < 2; dy++){\n",
    "\t\t\t\tfor(var dx = 0; dx < 2; dx++){\n",
    "\t\t\t\t\tif((x + dx < 28) && (y + dy < 28)){\n",
    "\t\t\t\t\t\tpixels[(y+dy) + (x+dx)*28] = 1\n",
    "\t\t\t\t\t}\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}else{\n",
    "            if(click == 1) set_value()\n",
    "\t\t\tclick = 0;\n",
    "\t\t}\n",
    "\t});\n",
    "\t\n",
    "\tfunction set_value(){\n",
    "\t\tvar result = \"\"\n",
    "\t\tfor(var i=0;i<28*28;i++) result += pixels[i] + \",\"\n",
    "\t\tvar kernel = IPython.notebook.kernel;\n",
    "\t\tkernel.execute(\"image = [\" + result + \"]\");\n",
    "\t}\n",
    "\t\n",
    "\tfunction clear_value(){\n",
    "        canvas.getContext(\"2d\").fillStyle = \"rgb(255,255,255)\";\n",
    "\t\tcanvas.getContext(\"2d\").fillRect(0,0,140,140);\n",
    "\t\tfor(var i=0;i<28*28;i++) pixels[i]=0\n",
    "\t}\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(input_form + javascript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n"
     ]
    }
   ],
   "source": [
    "print(len(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.38855631e-213]\n",
      " [4.19369931e-133]\n",
      " [8.92996288e-177]\n",
      " [3.97513074e-111]\n",
      " [1.06511625e-136]\n",
      " [5.07468604e-072]\n",
      " [2.29069488e-183]\n",
      " [1.14602456e-189]\n",
      " [1.03142826e-263]\n",
      " [1.00000000e+000]]\n",
      "network says  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the neural network withour own images\n",
    "img_data = numpy.array(image)\n",
    "img_data = img_data.reshape(1,784)\n",
    "matplotlib.pyplot.imshow(img_data.reshape(28,28), cmap='Greys', interpolation='None')\n",
    "\n",
    "# query the network\n",
    "outputs = n.query(img_data)\n",
    "print (outputs)\n",
    "\n",
    "# the index of the highest value corresponds to the label\n",
    "label = numpy.argmax(outputs)\n",
    "print(\"network says \", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
